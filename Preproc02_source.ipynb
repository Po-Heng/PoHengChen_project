{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263b7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import mne, os, pickle, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339fdda2",
   "metadata": {},
   "source": [
    "# setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e57f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  8  9 10 11 12 13 14 15 16 17 19 21 22 23 24 25]\n"
     ]
    }
   ],
   "source": [
    "# directories\n",
    "main_dir = '/Users/cl5564/Dropbox/Analysis/NTULingAmb/'\n",
    "os.chdir(main_dir) # change directory\n",
    "meg_dir = os.path.join(main_dir, '02_meg')  # meg directory\n",
    "mri_dir = os.path.join(main_dir, '03_mri')  # mri directory\n",
    "stc_dir = os.path.join(main_dir, '04_stc')  # stc directory\n",
    "\n",
    "# subject list\n",
    "subjects = np.arange(7, 25+1, 1)\n",
    "subjects = np.setdiff1d(subjects, [18, 20]) # exlude subjects: 018, 020\n",
    "print(subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee713aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/cl5564/Dropbox/Analysis/NTULingAmb/02_meg/025/025-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "126 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/cl5564/Dropbox/Analysis/NTULingAmb/02_meg/025/025_ambiguity-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...    1000.00 ms (ambiguous (dominant biasing))\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 32 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.1, 0] sec)\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...    1000.00 ms (ambiguous (subordinate biasing))\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 31 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.1, 0] sec)\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...    1000.00 ms (unambiguous)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 63 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.1, 0] sec)\n",
      "Extracting SQD Parameters from /Users/cl5564/Dropbox/Analysis/NTULingAmb/02_meg/025/025empty.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading 0 ... 179999  =      0.000 ...   179.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-12 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 441 samples (0.441 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 900 segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 157 out of 157 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used : 180000\n",
      "[done]\n",
      "Setting up the source space with the following parameters:\n",
      "\n",
      "SUBJECTS_DIR = /Users/cl5564/Dropbox/Analysis/NTULingAmb/03_mri\n",
      "Subject      = 025\n",
      "Surface      = white\n",
      "Icosahedron subdivision grade 4\n",
      "\n",
      ">>> 1. Creating the source space...\n",
      "\n",
      "Doing the icosahedral vertex picking...\n",
      "Loading /Users/cl5564/Dropbox/Analysis/NTULingAmb/03_mri/025/surf/lh.white...\n",
      "Mapping lh 025 -> ico (4) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /Users/cl5564/Dropbox/Analysis/NTULingAmb/03_mri/025/surf/lh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded lh.white 2562/163842 selected to source space (ico = 4)\n",
      "\n",
      "Loading /Users/cl5564/Dropbox/Analysis/NTULingAmb/03_mri/025/surf/rh.white...\n",
      "Mapping rh 025 -> ico (4) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /Users/cl5564/Dropbox/Analysis/NTULingAmb/03_mri/025/surf/rh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded rh.white 2562/163842 selected to source space (ico = 4)\n",
      "\n",
      "Calculating source space distances (limit=inf mm)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "You are now one step closer to computing the gain matrix\n",
      "Overwriting existing file.\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    2 source spaces written\n",
      "Creating the BEM geometry...\n",
      "Going from 5th to 4th subdivision of an icosahedron (n_tri: 20480 -> 5120)\n",
      "inner skull CM is  -0.45 -18.36   6.21 mm\n",
      "Surfaces passed the basic topology checks.\n",
      "Complete.\n",
      "\n",
      "Homogeneous model surface loaded.\n",
      "Computing the linear collocation solution...\n",
      "    Matrix coefficients...\n",
      "        inner skull (2562) -> inner skull (2562) ...\n",
      "    Inverting the coefficient matrix...\n",
      "Solution ready.\n",
      "BEM geometry computations complete.\n",
      "Overwriting existing file.\n",
      "Source space          : <SourceSpaces: [<surface (lh), n_vertices=163842, n_used=2562>, <surface (rh), n_vertices=163842, n_used=2562>] MRI (surface RAS) coords, subject '025', ~33.3 MB>\n",
      "MRI -> head transform : /Users/cl5564/Dropbox/Analysis/NTULingAmb/02_meg/025/025-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : instance of ConductorModel\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Read 2 source spaces a total of 5124 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999945  0.010438  0.000840       0.80 mm\n",
      "    -0.010472  0.996724  0.080195      18.20 mm\n",
      "    -0.000000 -0.080199  0.996779      44.60 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read 157 MEG channels from info\n",
      "105 coil definitions read\n",
      "Coordinate transformation: MEG device -> head\n",
      "     0.995188  0.042455 -0.088312      -1.05 mm\n",
      "    -0.014957  0.956520  0.291285      14.00 mm\n",
      "     0.096838 -0.288562  0.952551      89.57 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "MEG coil definitions created in head coordinates.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model instance of ConductorModel is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "Checking surface interior status for 2562 points...\n",
      "    Found  866/2562 points inside  an interior sphere of radius   47.3 mm\n",
      "    Found    0/2562 points outside an exterior sphere of radius   86.3 mm\n",
      "    Found    0/1696 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found    0/1696 points outside using solid angles\n",
      "    Total 2562/2562 points inside the surface\n",
      "Interior check completed in 1319.1 ms\n",
      "Checking surface interior status for 2562 points...\n",
      "    Found  812/2562 points inside  an interior sphere of radius   47.3 mm\n",
      "    Found    0/2562 points outside an exterior sphere of radius   86.3 mm\n",
      "    Found    0/1750 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found    0/1750 points outside using solid angles\n",
      "    Total 2562/2562 points inside the surface\n",
      "Interior check completed in 1344.7 ms\n",
      "\n",
      "Checking surface interior status for 157 points...\n",
      "    Found   0/157 points inside  an interior sphere of radius   47.3 mm\n",
      "    Found 157/157 points outside an exterior sphere of radius   86.3 mm\n",
      "    Found   0/  0 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found   0/  0 points outside using solid angles\n",
      "    Total 0/157 points inside the surface\n",
      "Interior check completed in 205.4 ms\n",
      "\n",
      "Composing the field computation matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MEG at 5124 source locations (free orientations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished.\n",
      "    Cartesian source orientations...\n",
      "    [done]\n",
      "Overwriting existing file.\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    2 source spaces written\n",
      "Computing inverse operator with 157 channels.\n",
      "    157 out of 157 channels remain after picking\n",
      "Selected 157 channels\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 1.1e-13 (2.2e-16 eps * 157 dim * 3.3  max singular value)\n",
      "    Estimated rank (mag): 157\n",
      "    MAG: rank 157 computed from 157 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 6.68741\n",
      "    scaling factor to adjust the trace = 6.74178e+20 (nchan = 157 nzero = 0)\n",
      "Overwriting existing file.\n",
      "Write inverse operator decomposition in /Users/cl5564/Dropbox/Analysis/NTULingAmb/02_meg/025/025-source-inv.fif...\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    2 source spaces written\n",
      "    Writing inverse operator info...\n",
      "    Writing noise covariance matrix.\n",
      "    Writing source covariance matrix.\n",
      "    Writing orientation priors.\n",
      "    [done]\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 32\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 157 (0 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"ambiguous (dominant biasing)\"...\n",
      "    Picked 157 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  88.5% variance\n",
      "    Combining the current components...\n",
      "    dSPM...\n",
      "[done]\n",
      "surface source space present ...\n",
      "Computing morph matrix...\n",
      "    Left-hemisphere map read.\n",
      "    Right-hemisphere map read.\n",
      "    5 smooth iterations done.\n",
      "    5 smooth iterations done.\n",
      "[done]\n",
      "[done]\n",
      "Writing STC to disk...\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "[done]\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 31\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 157 (0 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"ambiguous (subordinate biasing)\"...\n",
      "    Picked 157 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  85.6% variance\n",
      "    Combining the current components...\n",
      "    dSPM...\n",
      "[done]\n",
      "surface source space present ...\n",
      "Computing morph matrix...\n",
      "    Left-hemisphere map read.\n",
      "    Right-hemisphere map read.\n",
      "    5 smooth iterations done.\n",
      "    5 smooth iterations done.\n",
      "[done]\n",
      "[done]\n",
      "Writing STC to disk...\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "[done]\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 63\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 157 (0 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"unambiguous\"...\n",
      "    Picked 157 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  88.8% variance\n",
      "    Combining the current components...\n",
      "    dSPM...\n",
      "[done]\n",
      "surface source space present ...\n",
      "Computing morph matrix...\n",
      "    Left-hemisphere map read.\n",
      "    Right-hemisphere map read.\n",
      "    5 smooth iterations done.\n",
      "    5 smooth iterations done.\n",
      "[done]\n",
      "[done]\n",
      "Writing STC to disk...\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# define variables\n",
    "tmin = -0.1\n",
    "tmax = 1.0\n",
    "baseline = (None, 0)  # tmin~0 , -0.1s~0s   # none = start from tmin.\n",
    "conditions = ['amb_dom', 'amb_sub', 'unamb']\n",
    "\n",
    "for s, sid in enumerate(subjects):\n",
    "    \n",
    "    # load data\n",
    "    subj = ('%.3d') %(sid)\n",
    "    subj_dir = os.path.join(meg_dir, '%s') %(subj)\n",
    "    epochs_fname = os.path.join(subj_dir, '%s-epo.fif') %(subj)\n",
    "    epochs = mne.read_epochs(epochs_fname)\n",
    "    evoked_fname = os.path.join(subj_dir, '%s_ambiguity-ave.fif') %(subj)\n",
    "    evoked = mne.read_evokeds(evoked_fname)\n",
    "    info = epochs.info\n",
    "    \n",
    "    # define file names for source analysis\n",
    "    trans_fname = os.path.join(subj_dir, '%s-trans.fif') %(subj)\n",
    "    bem_fname = os.path.join(mri_dir, '%s', 'bem', '%s-inner_skull-bem-sol.fif') %(subj, subj)\n",
    "    src_fname = os.path.join(mri_dir, '%s', 'bem', '%s-ico-4-src.fif') %(subj, subj)\n",
    "    fwd_fname = os.path.join(subj_dir, '%s-fwd.fif') %(subj)\n",
    "    cov_fname = os.path.join(subj_dir, '%s-cov.fif') %(subj)\n",
    "    inv_fname = os.path.join(subj_dir, '%s-source-inv.fif') %(subj)\n",
    "    \n",
    "    # empty room for denoising\n",
    "    em_fname = os.path.join(subj_dir, '%sempty.con') %(subj)\n",
    "    raw_em = mne.io.kit.read_raw_kit(em_fname)\n",
    "    raw_em.load_data().pick_types(meg=True, stim=False).filter(0, 30, phase= 'zero-double')\n",
    "    # compute noise covariance\n",
    "    noise_cov = mne.compute_raw_covariance(raw_em, tmin=0, tmax=None)\n",
    "    \n",
    "    # compute the source space\n",
    "    src = mne.setup_source_space(subject=subj, spacing='ico4', subjects_dir=mri_dir)\n",
    "    src.save(src_fname, overwrite=True)\n",
    "    #src = mne.read_source_spaces(src_fname)\n",
    "    \n",
    "    # bem model\n",
    "    conductivity = (0.3,)\n",
    "    model = mne.make_bem_model(subject=subj, ico=4, conductivity=conductivity, subjects_dir=mri_dir)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    mne.bem.write_bem_solution(bem_fname, bem ,overwrite=True)\n",
    "    \n",
    "    # forward model\n",
    "    fwd = mne.make_forward_solution(info=info, trans=trans_fname, src=src, bem=bem, \n",
    "                                    meg=True, eeg=False, mindist=5.0, ignore_ref=True)    \n",
    "    fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=False, force_fixed=False, use_cps=True)\n",
    "    #不限制axis旋轉角度=free orientation.\n",
    "    mne.write_forward_solution(fwd_fname, fwd_fixed, overwrite=True)\n",
    "    #fwd = mne.read_forward_solution(fwd_fname)\n",
    "\n",
    "    # inverse operation\n",
    "    SNR = 3 # 3 for ANOVAs, 2 for regressions\n",
    "    lambda2 = 1.0 / SNR ** 2\n",
    "    # free orientation.\n",
    "    inv = mne.minimum_norm.make_inverse_operator(info, fwd_fixed, noise_cov, loose=1.0, \n",
    "                                                 depth=None, fixed=False, verbose=True)\n",
    "    mne.minimum_norm.write_inverse_operator(inv_fname, inv, overwrite=True)\n",
    "    \n",
    "    for c, cond in enumerate(conditions):\n",
    "        \n",
    "        # create stc for each condition\n",
    "        # pick ori can create constraint for signal orientation.\n",
    "        evk = evoked[c]\n",
    "        stc = mne.minimum_norm.apply_inverse(evk, inv, lambda2, 'dSPM', verbose=True, pick_ori=None)\n",
    "        \n",
    "        # morph to fsaverage template\n",
    "        morph = mne.compute_source_morph(stc, subject_from=subj, subject_to='fsaverage',\n",
    "                                         subjects_dir=mri_dir, spacing=4)\n",
    "        stc_fsavg = morph.apply(stc)\n",
    "        \n",
    "        # save stc file\n",
    "        stc_fname = os.path.join(stc_dir, '%s', '%s_stc_%s') %(cond, subj, cond)\n",
    "        stc_fsavg.save(stc_fname, overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbfc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
